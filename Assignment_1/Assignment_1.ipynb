{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "302d2d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading the packages\n",
    "# uncomment all the lines to install the packages\n",
    "\n",
    "#import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# open the nltk downloader\n",
    "# note that the downloader might be minimized in your toolbar\n",
    "# the downloader is a modal window, so the Jupyter notebook will wait for you to do something with it\n",
    "#nltk.download()\n",
    "\n",
    "#!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83b13f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Tokenize the texts in the text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1107e1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized text written to: E:\\MS_Course_Notes\\COMP_293C\\Assignments\\Assignment_1\\q1_tokenized_output.txt\n"
     ]
    }
   ],
   "source": [
    "#using nltk\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "import pickle\n",
    "# Open the input file for reading\n",
    "# change the path of the input file according to your path location\n",
    "with open(\"E:\\\\MS_Course_Notes\\\\COMP_293C\\\\Assignments\\\\Assignment_1\\\\input_data.txt\", 'r') as file:\n",
    "    input_text = file.read()\n",
    "\n",
    "tokenized_text = word_tokenize(input_text)\n",
    "\n",
    "# Specify the path for the output file to save the tokenized text\n",
    "output_file_path = \"E:\\\\MS_Course_Notes\\\\COMP_293C\\\\Assignments\\\\Assignment_1\\\\q1_tokenized_output.txt\"\n",
    "\n",
    "# Write the tokenized text to the output file\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    output_file.write(str(tokenized_text))\n",
    "\n",
    "print(\"Tokenized text written to:\", output_file_path)\n",
    "#print the tokenized text\n",
    "#print(tokenized_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20a288f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Count word frequencies in the texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "670b0943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count word frequencies written to: E:\\MS_Course_Notes\\COMP_293C\\Assignments\\Assignment_1\\q2_frequency_output.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 74, 'the': 70, 'to': 55, ':': 52, '.': 44, 'of': 41, 'your': 40, 'for': 35, 'are': 26, 'and': 23, ...})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "\n",
    "freq_dist = FreqDist(tokenized_text)\n",
    "\n",
    "# Convert the frequency distribution to a dictionary\n",
    "freq_dict = dict(freq_dist)\n",
    "\n",
    "\n",
    "# Specify the path for the output file to save the tokenized text\n",
    "output_file_path = \"E:\\\\MS_Course_Notes\\\\COMP_293C\\\\Assignments\\\\Assignment_1\\\\q2_frequency_output.txt\"\n",
    "\n",
    "# Write the tokenized text to the output file\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    output_file.write(str(freq_dict))\n",
    "\n",
    "print(\"Count word frequencies written to:\", output_file_path)\n",
    "FreqDist(tokenized_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44dac5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Perform part-of-speech (POS) tagging on the tokenized words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a01523c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform part-of-speech (POS) tagging on the tokenized words written to: E:\\MS_Course_Notes\\COMP_293C\\Assignments\\Assignment_1\\q3_pos_output.txt\n"
     ]
    }
   ],
   "source": [
    "pos_tag_text = nltk.pos_tag(tokenized_text)\n",
    "\n",
    "# Specify the path for the output file to save the tokenized text\n",
    "output_file_path = \"E:\\\\MS_Course_Notes\\\\COMP_293C\\\\Assignments\\\\Assignment_1\\\\q3_pos_output.txt\"\n",
    "\n",
    "# Write the tokenized text to the output file\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    output_file.write(str(pos_tag_text))\n",
    "\n",
    "print(\"Perform part-of-speech (POS) tagging on the tokenized words written to:\", output_file_path)\n",
    "\n",
    "#print(pos_tag_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07db0b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4. Perform named entity recognition (NER) on the texts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d31830c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perform named entity recognition (NER) on the texts written to: E:\\MS_Course_Notes\\COMP_293C\\Assignments\\Assignment_1\\q4_pos_output.txt\n"
     ]
    }
   ],
   "source": [
    "# Use NLTK's NER chunker\n",
    "ner_tag_texts = nltk.chunk.ne_chunk(pos_tag_text)\n",
    "\n",
    "# 'ner_tag_texts' now contains a tree structure with named entities recognized\n",
    "# Extract named entities as a list:\n",
    "named_entities = []\n",
    "for subtree in ner_tag_texts:\n",
    "    if isinstance(subtree, nltk.Tree):\n",
    "        entity = \" \".join([word for word, tag in subtree.leaves()])\n",
    "        named_entities.append((entity, subtree.label()))\n",
    "        \n",
    "# Specify the path for the output file to save the tokenized text\n",
    "output_file_path = \"E:\\\\MS_Course_Notes\\\\COMP_293C\\\\Assignments\\\\Assignment_1\\\\q4_pos_output.txt\"\n",
    "\n",
    "# Write the tokenized text to the output file\n",
    "with open(output_file_path, 'w') as output_file:\n",
    "    output_file.write(str(named_entities))\n",
    "\n",
    "print(\"Perform named entity recognition (NER) on the texts written to:\", output_file_path)        \n",
    "#print(named_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffe0f6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Displaying the most frequent 10 words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b92c31ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP imports\n",
    "import nltk\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "# general numerical and visualization imports\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65b0bd4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5. Displaying the most frequent 10 words saved as: E:\\MS_Course_Notes\\COMP_293C\\Assignments\\Assignment_1\\q5_frequent_10_words_bar_plot.png\n"
     ]
    }
   ],
   "source": [
    "#displaying the most frequent 10 words\n",
    "\n",
    "from nltk import FreqDist\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # 'Agg' backend for saving plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'tokens' is your list of tokens\n",
    "word_freq = FreqDist(tokenized_text)\n",
    "\n",
    "# Get the 10 most common words\n",
    "most_common_words = word_freq.most_common(10)\n",
    "\n",
    "all_fdist = pd.Series(dict(most_common_words))\n",
    "# Setting fig and ax into variables\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "# Plot with Seaborn plotting tools\n",
    "plt.xticks(rotation = 60)\n",
    "plt.title(\"Frequency -- Top 10 Words in the input text file\",\n",
    "fontsize = 25)\n",
    "plt.xlabel(\"Words\", fontsize = 25)\n",
    "plt.ylabel(\"Frequency\", fontsize = 25)\n",
    "all_plot = sns.barplot(x = all_fdist.index, y = all_fdist.values,\n",
    "ax=ax)\n",
    "plt.xticks(rotation=50)\n",
    "#to display in UI\n",
    "#plt.show()\n",
    "\n",
    "# Specify the path for the output image file where you want to save the plot\n",
    "output_image_path = \"E:\\\\MS_Course_Notes\\\\COMP_293C\\\\Assignments\\\\Assignment_1\\\\q5_frequent_10_words_bar_plot.png\"\n",
    "\n",
    "# Save the plot as an image file\n",
    "plt.savefig(output_image_path, bbox_inches='tight')  # 'bbox_inches' prevents trimming of labels\n",
    "\n",
    "print(\"5. Displaying the most frequent 10 words saved as:\", output_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9eb9807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Compute a word cloud from the word frequency distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e076744c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6. Compute a word cloud from the word frequency distribution saved as: E:\\MS_Course_Notes\\COMP_293C\\Assignments\\Assignment_1\\q6_word_cloud_frequency.png\n"
     ]
    }
   ],
   "source": [
    "# displaying a WordCloud\n",
    "from wordcloud import WordCloud\n",
    "wordcloud = WordCloud(background_color = 'white',\n",
    "\n",
    "max_words = 25,\n",
    "relative_scaling = 0,\n",
    "width = 600,height = 300,\n",
    "max_font_size = 150,\n",
    "colormap = 'Dark2',\n",
    "min_font_size = 10).generate_from_frequencies(all_fdist)\n",
    "# Display the generated image:\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "#to display in UI\n",
    "#plt.show()\n",
    "# Specify the path for the output image file where you want to save the plot\n",
    "output_image_path = \"E:\\\\MS_Course_Notes\\\\COMP_293C\\\\Assignments\\\\Assignment_1\\\\q6_word_cloud_frequency.png\"\n",
    "\n",
    "# Save the plot as an image file\n",
    "plt.savefig(output_image_path, bbox_inches='tight')  # 'bbox_inches' prevents trimming of labels\n",
    "\n",
    "print(\"6. Compute a word cloud from the word frequency distribution saved as:\", output_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cb0f8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7. Display the frequencies of the parts of speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0f3e606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7. Display the frequencies of the parts of speech. saved as: E:\\MS_Course_Notes\\COMP_293C\\Assignments\\Assignment_1\\q7_frequency_pos.png\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Count the occurrences of each POS tag\n",
    "pos_freq = Counter(tag for word, tag in pos_tag_text)\n",
    "\n",
    "# Extract the tags and their frequencies\n",
    "tags = list(pos_freq.keys())\n",
    "frequencies = list(pos_freq.values())\n",
    "\n",
    "# Define a custom color palette using seaborn\n",
    "custom_palette = sns.color_palette(\"Set1\", len(tags))\n",
    "\n",
    "# Create a bar plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Iterate through tags and frequencies and assign custom colors\n",
    "for i, (tag, freq) in enumerate(zip(tags, frequencies)):\n",
    "    plt.bar(tag, freq, color=custom_palette[i])\n",
    "\n",
    "plt.xlabel(\"Part of Speech\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Part of Speech Frequency in input text file\")\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels for better visibility\n",
    "plt.tight_layout()  # Ensure labels are not cut off\n",
    "#to show in the front end\n",
    "#plt.show()\n",
    "\n",
    "# Specify the path for the output image file where you want to save the plot\n",
    "output_image_path = \"E:\\\\MS_Course_Notes\\\\COMP_293C\\\\Assignments\\\\Assignment_1\\\\q7_frequency_pos.png\"\n",
    "\n",
    "# Save the plot as an image file\n",
    "plt.savefig(output_image_path, bbox_inches='tight')  # 'bbox_inches' prevents trimming of labels\n",
    "\n",
    "print(\"7. Display the frequencies of the parts of speech. saved as:\", output_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8680ce6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
